{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. PyTorch를 통한 선형회귀분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 선형 회귀분석에 대해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 단순 선형회귀분석 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두가지의 **연속형 변수** 사이의 관계에 대해 이해하게 해 준다.\n",
    "- 예시\n",
    "    - x: 독립 변수\n",
    "        - 무게\n",
    "    - y: 종속 변수\n",
    "        - 키\n",
    "    - y = $\\alpha x + \\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 단순 선형회귀분석의 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1)\n",
    "n = 50\n",
    "x = np.random.randn(n)\n",
    "y = x * np.random.rand(n)\n",
    "\n",
    "colors = np.random.rand(n)\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "\n",
    "plt.scatter(x, y, c=colors, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 선형 회귀분석의 목적\n",
    "\n",
    "- 포인트들과 선의 사이를 최소화($y = \\alpha x + \\beta$)\n",
    "- 조정하기\n",
    "    - 계수: $\\alpha$\n",
    "    - 편향/절편 : $\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PyTorch를 통해 선형 회귀 모델 구축하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 예"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 계수: $\\alpha$ = 2\n",
    "- 편향/절편: $\\beta$ = 1\n",
    "- 식: $y = 2x + 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 토이 데이터셋 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [i for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy로 변환\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중요: 2차원이 필요하다\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = 2x + 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 4.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 7.],\n",
       "       [ 8.],\n",
       "       [ 9.],\n",
       "       [10.]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values = [2*i + 1 for i in x_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중요: 2차원이 필요하다\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 모델 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중요한 선언들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성하기\n",
    "\n",
    "1. 선형 모델\n",
    "    - True Equation: $y = 2x + 1$\n",
    "2. 포워드\n",
    "    - Example\n",
    "        - Input $x = 1$\n",
    "        - Output $\\hat{y}=?$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 생성\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressionModel, self).__init__() # nn.Module을 상속받기 위한 것\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 클래스 설명하기\n",
    "- 인풋 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "- 바라는 아웃풋 : [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "output_size = 1\n",
    "\n",
    "model = LinearRegressionModel(input_size, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Class 인스턴스화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MSE Loss : Mean Squared Error\n",
    "- $MSE = \\frac{1}{2}\\sum^{n}_{i=1}(\\hat{y_i} - y_i)$\n",
    "    - $\\hat{y}$: prediction\n",
    "    - $y$: true value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최적화 Class 인스턴스화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simplified equation\n",
    "    - $\\theta = \\theta - \\eta \\cdot \\nabla_{\\theta}$\n",
    "        - $\\theta$: parameters (our variables)\n",
    "        - $\\eta$: learning rate (how fast we want to learn)\n",
    "        - $\\nabla_{\\theta}$: parameters' gradients\n",
    "        \n",
    "    - Even simplier equation\n",
    "        - parameters = parameters - learning_rate * parameters_gradients\n",
    "            - parameters: $\\alpha$ and $\\beta$ in $y = \\alpha x + \\beta$\n",
    "            - desired parameters: $\\alpha = 2$ and $\\beta = 1$ in $y = 2x + 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습시키기\n",
    "- 1 에폭: x 전체 데이터를 한번 다 도는것\n",
    "    - 100 에폭:\n",
    "        - 100x mapping x_train = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "- Process\n",
    "    1. inputs/labes을 variables로 바꾼다.\n",
    "    2. gradient buffer 들을 비워준다.\n",
    "    3. 인풋에 기반한 아웃풋을 내어 준다.\n",
    "    4. loss를 구한다.\n",
    "    5. 파라미터에 대한 그라디언트들 구하기\n",
    "    6. 그라디언트를 이용하여 파라미터 업데이트\n",
    "        - 파라미터 = 파라미터 - 학습률 * 파라미터 그라디언트\n",
    "    7. 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 179.47335815429688\n",
      "epoch 2, loss 14.640972137451172\n",
      "epoch 3, loss 1.1960983276367188\n",
      "epoch 4, loss 0.09942218661308289\n",
      "epoch 5, loss 0.009948421269655228\n",
      "epoch 6, loss 0.0026299962773919106\n",
      "epoch 7, loss 0.0020127224270254374\n",
      "epoch 8, loss 0.0019422810291871428\n",
      "epoch 9, loss 0.0019166857236996293\n",
      "epoch 10, loss 0.0018949602963402867\n",
      "epoch 11, loss 0.0018737673526629806\n",
      "epoch 12, loss 0.001852841000072658\n",
      "epoch 13, loss 0.0018321448005735874\n",
      "epoch 14, loss 0.001811694703064859\n",
      "epoch 15, loss 0.0017914618365466595\n",
      "epoch 16, loss 0.0017714510904625058\n",
      "epoch 17, loss 0.0017516856314614415\n",
      "epoch 18, loss 0.0017320991028100252\n",
      "epoch 19, loss 0.0017127792816609144\n",
      "epoch 20, loss 0.001693644793704152\n",
      "epoch 21, loss 0.0016747366171330214\n",
      "epoch 22, loss 0.0016560322837904096\n",
      "epoch 23, loss 0.0016375445993617177\n",
      "epoch 24, loss 0.0016192689072340727\n",
      "epoch 25, loss 0.0016011812258511782\n",
      "epoch 26, loss 0.0015832908684387803\n",
      "epoch 27, loss 0.0015656145988032222\n",
      "epoch 28, loss 0.001548119238577783\n",
      "epoch 29, loss 0.0015308383153751493\n",
      "epoch 30, loss 0.001513735274784267\n",
      "epoch 31, loss 0.0014968429459258914\n",
      "epoch 32, loss 0.0014801257057115436\n",
      "epoch 33, loss 0.0014635984553024173\n",
      "epoch 34, loss 0.0014472712064161897\n",
      "epoch 35, loss 0.0014311004197224975\n",
      "epoch 36, loss 0.0014151007635518909\n",
      "epoch 37, loss 0.0013993139145895839\n",
      "epoch 38, loss 0.001383683760650456\n",
      "epoch 39, loss 0.001368244062177837\n",
      "epoch 40, loss 0.001352971768938005\n",
      "epoch 41, loss 0.0013378566363826394\n",
      "epoch 42, loss 0.001322899479418993\n",
      "epoch 43, loss 0.0013081306824460626\n",
      "epoch 44, loss 0.001293520093895495\n",
      "epoch 45, loss 0.001279073883779347\n",
      "epoch 46, loss 0.0012648091651499271\n",
      "epoch 47, loss 0.0012506697094067931\n",
      "epoch 48, loss 0.0012367102317512035\n",
      "epoch 49, loss 0.0012228976702317595\n",
      "epoch 50, loss 0.001209232141263783\n",
      "epoch 51, loss 0.001195726334117353\n",
      "epoch 52, loss 0.0011823860695585608\n",
      "epoch 53, loss 0.001169192255474627\n",
      "epoch 54, loss 0.001156131038442254\n",
      "epoch 55, loss 0.0011432254686951637\n",
      "epoch 56, loss 0.0011304463259875774\n",
      "epoch 57, loss 0.0011178241111338139\n",
      "epoch 58, loss 0.0011053337948396802\n",
      "epoch 59, loss 0.0010930082062259316\n",
      "epoch 60, loss 0.0010808007791638374\n",
      "epoch 61, loss 0.001068723271600902\n",
      "epoch 62, loss 0.001056801644153893\n",
      "epoch 63, loss 0.0010449937544763088\n",
      "epoch 64, loss 0.0010333332465961576\n",
      "epoch 65, loss 0.001021787989884615\n",
      "epoch 66, loss 0.001010380918160081\n",
      "epoch 67, loss 0.000999084790237248\n",
      "epoch 68, loss 0.0009879376739263535\n",
      "epoch 69, loss 0.0009768992895260453\n",
      "epoch 70, loss 0.000965990184340626\n",
      "epoch 71, loss 0.0009552050614729524\n",
      "epoch 72, loss 0.0009445406030863523\n",
      "epoch 73, loss 0.0009339898824691772\n",
      "epoch 74, loss 0.0009235689067281783\n",
      "epoch 75, loss 0.00091325439279899\n",
      "epoch 76, loss 0.0009030584478750825\n",
      "epoch 77, loss 0.0008929730975069106\n",
      "epoch 78, loss 0.0008830007282085717\n",
      "epoch 79, loss 0.0008731400012038648\n",
      "epoch 80, loss 0.0008633775287307799\n",
      "epoch 81, loss 0.000853745499625802\n",
      "epoch 82, loss 0.0008442109683528543\n",
      "epoch 83, loss 0.0008347851689904928\n",
      "epoch 84, loss 0.0008254533750005066\n",
      "epoch 85, loss 0.0008162425365298986\n",
      "epoch 86, loss 0.0008071368210949004\n",
      "epoch 87, loss 0.000798126682639122\n",
      "epoch 88, loss 0.0007892051944509149\n",
      "epoch 89, loss 0.0007803969201631844\n",
      "epoch 90, loss 0.0007716836989857256\n",
      "epoch 91, loss 0.0007630718755535781\n",
      "epoch 92, loss 0.0007545429980382323\n",
      "epoch 93, loss 0.0007461179047822952\n",
      "epoch 94, loss 0.0007377853034995496\n",
      "epoch 95, loss 0.0007295366958715022\n",
      "epoch 96, loss 0.0007214026409201324\n",
      "epoch 97, loss 0.0007133400649763644\n",
      "epoch 98, loss 0.0007053790614008904\n",
      "epoch 99, loss 0.0006975060096010566\n",
      "epoch 100, loss 0.0006897126440890133\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    # numpy 배열을 torch 변수로 변환\n",
    "    inputs = Variable(torch.from_numpy(x_train))\n",
    "    labels = Variable(torch.from_numpy(y_train))\n",
    "    \n",
    "    # 파라미터들에 대한 Gradients 비우기\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # output을 내기 위한 Forward\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Loss 계산하기\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    \n",
    "    # 파라미터들에 관한 gradients들 얻기\n",
    "    loss.backward()\n",
    "    \n",
    "    \n",
    "    # 파라미터들 업데이트\n",
    "    optimizer.step()\n",
    "    \n",
    "    print (f'epoch {epoch}, loss {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 두 식은 그 기능이 같다.\n",
    "# model.forward(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "# model(Variable(torch.from_numpy(x_train))).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0488532],\n",
       "       [ 3.041818 ],\n",
       "       [ 5.0347824],\n",
       "       [ 7.027747 ],\n",
       "       [ 9.020712 ],\n",
       "       [11.013677 ],\n",
       "       [13.006641 ],\n",
       "       [14.999606 ],\n",
       "       [16.99257  ],\n",
       "       [18.985537 ],\n",
       "       [20.9785   ]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Purely inference\n",
    "predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [15.],\n",
       "       [17.],\n",
       "       [19.],\n",
       "       [21.]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = 2x + 1\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clear Figure\n",
    "plt.clf()\n",
    "\n",
    "# Get predictions\n",
    "predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "\n",
    "# Plot true data\n",
    "plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
    "\n",
    "# Plot predictions\n",
    "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
    "\n",
    "# Legend and plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = False\n",
    "if save_model is True:\n",
    "    # Saves only parameters\n",
    "    # alpha & beta\n",
    "    torch.save(model.state_dict(), 'awesome_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "if load_model is True:\n",
    "    model.load_state_dict(torch.load('awesome_model.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PyTorch (GPU)를 통한 선형회귀 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 142.19232177734375\n",
      "epoch 2, loss 11.605179786682129\n",
      "epoch 3, loss 0.9535170197486877\n",
      "epoch 4, loss 0.08461693674325943\n",
      "epoch 5, loss 0.01366720162332058\n",
      "epoch 6, loss 0.007804561872035265\n",
      "epoch 7, loss 0.007251621689647436\n",
      "epoch 8, loss 0.007132682017982006\n",
      "epoch 9, loss 0.007049898616969585\n",
      "epoch 10, loss 0.006970921065658331\n",
      "epoch 11, loss 0.0068930271081626415\n",
      "epoch 12, loss 0.006816074252128601\n",
      "epoch 13, loss 0.006739972624927759\n",
      "epoch 14, loss 0.006664700340479612\n",
      "epoch 15, loss 0.006590262055397034\n",
      "epoch 16, loss 0.0065166945569217205\n",
      "epoch 17, loss 0.006443887483328581\n",
      "epoch 18, loss 0.006371938157826662\n",
      "epoch 19, loss 0.0063008214347064495\n",
      "epoch 20, loss 0.006230439059436321\n",
      "epoch 21, loss 0.0061608548276126385\n",
      "epoch 22, loss 0.0060920859687030315\n",
      "epoch 23, loss 0.0060240537859499454\n",
      "epoch 24, loss 0.005956783425062895\n",
      "epoch 25, loss 0.005890266504138708\n",
      "epoch 26, loss 0.00582447974011302\n",
      "epoch 27, loss 0.005759454797953367\n",
      "epoch 28, loss 0.005695142317563295\n",
      "epoch 29, loss 0.0056315273977816105\n",
      "epoch 30, loss 0.005568619351834059\n",
      "epoch 31, loss 0.005506440531462431\n",
      "epoch 32, loss 0.005444969516247511\n",
      "epoch 33, loss 0.005384167190641165\n",
      "epoch 34, loss 0.005324041470885277\n",
      "epoch 35, loss 0.005264613777399063\n",
      "epoch 36, loss 0.005205795634537935\n",
      "epoch 37, loss 0.005147670861333609\n",
      "epoch 38, loss 0.005090196151286364\n",
      "epoch 39, loss 0.005033332854509354\n",
      "epoch 40, loss 0.004977142903953791\n",
      "epoch 41, loss 0.004921548534184694\n",
      "epoch 42, loss 0.004866588860750198\n",
      "epoch 43, loss 0.004812241066247225\n",
      "epoch 44, loss 0.004758511204272509\n",
      "epoch 45, loss 0.004705376457422972\n",
      "epoch 46, loss 0.004652828443795443\n",
      "epoch 47, loss 0.004600859247148037\n",
      "epoch 48, loss 0.004549500998109579\n",
      "epoch 49, loss 0.004498685710132122\n",
      "epoch 50, loss 0.004448477644473314\n",
      "epoch 51, loss 0.004398800898343325\n",
      "epoch 52, loss 0.0043496862053871155\n",
      "epoch 53, loss 0.004301088396459818\n",
      "epoch 54, loss 0.00425306661054492\n",
      "epoch 55, loss 0.004205559380352497\n",
      "epoch 56, loss 0.004158631432801485\n",
      "epoch 57, loss 0.004112193826586008\n",
      "epoch 58, loss 0.004066258203238249\n",
      "epoch 59, loss 0.0040208701975643635\n",
      "epoch 60, loss 0.003975959494709969\n",
      "epoch 61, loss 0.003931552637368441\n",
      "epoch 62, loss 0.0038876542821526527\n",
      "epoch 63, loss 0.0038442551158368587\n",
      "epoch 64, loss 0.003801320679485798\n",
      "epoch 65, loss 0.003758866572752595\n",
      "epoch 66, loss 0.003716890001669526\n",
      "epoch 67, loss 0.003675393760204315\n",
      "epoch 68, loss 0.0036343643441796303\n",
      "epoch 69, loss 0.003593769622966647\n",
      "epoch 70, loss 0.003553620772436261\n",
      "epoch 71, loss 0.003513926174491644\n",
      "epoch 72, loss 0.0034747072495520115\n",
      "epoch 73, loss 0.003435879247263074\n",
      "epoch 74, loss 0.003397527150809765\n",
      "epoch 75, loss 0.0033595904242247343\n",
      "epoch 76, loss 0.0033221000339835882\n",
      "epoch 77, loss 0.0032849744893610477\n",
      "epoch 78, loss 0.0032482952810823917\n",
      "epoch 79, loss 0.0032120279502123594\n",
      "epoch 80, loss 0.0031761459540575743\n",
      "epoch 81, loss 0.0031407021451741457\n",
      "epoch 82, loss 0.003105610841885209\n",
      "epoch 83, loss 0.0030709162820130587\n",
      "epoch 84, loss 0.0030366533901542425\n",
      "epoch 85, loss 0.0030027253087610006\n",
      "epoch 86, loss 0.0029691806994378567\n",
      "epoch 87, loss 0.0029360561165958643\n",
      "epoch 88, loss 0.0029032453894615173\n",
      "epoch 89, loss 0.0028708295430988073\n",
      "epoch 90, loss 0.002838765736669302\n",
      "epoch 91, loss 0.0028070842381566763\n",
      "epoch 92, loss 0.002775726607069373\n",
      "epoch 93, loss 0.00274473475292325\n",
      "epoch 94, loss 0.00271409610286355\n",
      "epoch 95, loss 0.002683775732293725\n",
      "epoch 96, loss 0.0026538006495684385\n",
      "epoch 97, loss 0.0026241650339215994\n",
      "epoch 98, loss 0.002594871912151575\n",
      "epoch 99, loss 0.0025658863596618176\n",
      "epoch 100, loss 0.002537231193855405\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "'''\n",
    "STEP 1: CREATE MODEL CLASS\n",
    "'''\n",
    "class LinearRegressionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 2: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "\n",
    "model = LinearRegressionModel(input_size, output_size)\n",
    "\n",
    "'''\n",
    "STEP 3: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 5: TRAIN THE MODEL\n",
    "'''\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    # Convert numpy array to torch Variable\n",
    "    inputs = Variable(torch.from_numpy(x_train))\n",
    "    labels = Variable(torch.from_numpy(y_train))\n",
    "    \n",
    "    # Clear gradients w.r.t. parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward to get output\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Calculate Loss\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Getting gradients w.r.t. parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Updating parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    print (f'epoch {epoch}, loss {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU: GPU를 켜 둬야 하는 두 가지\n",
    "- model\n",
    "- variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 129.62646484375\n",
      "epoch 2, loss 10.608016967773438\n",
      "epoch 3, loss 0.8996660709381104\n",
      "epoch 4, loss 0.10740221291780472\n",
      "epoch 5, loss 0.042399823665618896\n",
      "epoch 6, loss 0.03672226518392563\n",
      "epoch 7, loss 0.03588761389255524\n",
      "epoch 8, loss 0.03545224294066429\n",
      "epoch 9, loss 0.03505358844995499\n",
      "epoch 10, loss 0.03466193377971649\n",
      "epoch 11, loss 0.034274812787771225\n",
      "epoch 12, loss 0.03389202430844307\n",
      "epoch 13, loss 0.03351353481411934\n",
      "epoch 14, loss 0.03313937410712242\n",
      "epoch 15, loss 0.032769303768873215\n",
      "epoch 16, loss 0.03240341693162918\n",
      "epoch 17, loss 0.03204149380326271\n",
      "epoch 18, loss 0.03168370947241783\n",
      "epoch 19, loss 0.03132999315857887\n",
      "epoch 20, loss 0.03098013997077942\n",
      "epoch 21, loss 0.03063408099114895\n",
      "epoch 22, loss 0.030291950330138206\n",
      "epoch 23, loss 0.029953746125102043\n",
      "epoch 24, loss 0.029619229957461357\n",
      "epoch 25, loss 0.02928854711353779\n",
      "epoch 26, loss 0.02896135300397873\n",
      "epoch 27, loss 0.02863803692162037\n",
      "epoch 28, loss 0.028318198397755623\n",
      "epoch 29, loss 0.028001977130770683\n",
      "epoch 30, loss 0.027689253911376\n",
      "epoch 31, loss 0.02738013118505478\n",
      "epoch 32, loss 0.02707434818148613\n",
      "epoch 33, loss 0.02677197940647602\n",
      "epoch 34, loss 0.026473013684153557\n",
      "epoch 35, loss 0.026177382096648216\n",
      "epoch 36, loss 0.02588510327041149\n",
      "epoch 37, loss 0.025595970451831818\n",
      "epoch 38, loss 0.025310182943940163\n",
      "epoch 39, loss 0.025027621537446976\n",
      "epoch 40, loss 0.024748027324676514\n",
      "epoch 41, loss 0.02447172813117504\n",
      "epoch 42, loss 0.02419840544462204\n",
      "epoch 43, loss 0.023928266018629074\n",
      "epoch 44, loss 0.023661063984036446\n",
      "epoch 45, loss 0.023396825417876244\n",
      "epoch 46, loss 0.023135559633374214\n",
      "epoch 47, loss 0.02287721075117588\n",
      "epoch 48, loss 0.022621752694249153\n",
      "epoch 49, loss 0.02236917056143284\n",
      "epoch 50, loss 0.022119328379631042\n",
      "epoch 51, loss 0.021872367709875107\n",
      "epoch 52, loss 0.02162811905145645\n",
      "epoch 53, loss 0.021386494860053062\n",
      "epoch 54, loss 0.02114769071340561\n",
      "epoch 55, loss 0.020911555737257004\n",
      "epoch 56, loss 0.020678026601672173\n",
      "epoch 57, loss 0.02044714242219925\n",
      "epoch 58, loss 0.020218826830387115\n",
      "epoch 59, loss 0.019993066787719727\n",
      "epoch 60, loss 0.019769752398133278\n",
      "epoch 61, loss 0.019548991695046425\n",
      "epoch 62, loss 0.019330698996782303\n",
      "epoch 63, loss 0.01911487616598606\n",
      "epoch 64, loss 0.018901392817497253\n",
      "epoch 65, loss 0.01869029738008976\n",
      "epoch 66, loss 0.018481634557247162\n",
      "epoch 67, loss 0.01827520877122879\n",
      "epoch 68, loss 0.018071213737130165\n",
      "epoch 69, loss 0.017869368195533752\n",
      "epoch 70, loss 0.017669813707470894\n",
      "epoch 71, loss 0.01747247576713562\n",
      "epoch 72, loss 0.017277367413043976\n",
      "epoch 73, loss 0.01708447001874447\n",
      "epoch 74, loss 0.016893642023205757\n",
      "epoch 75, loss 0.01670502871274948\n",
      "epoch 76, loss 0.01651849038898945\n",
      "epoch 77, loss 0.01633402518928051\n",
      "epoch 78, loss 0.016151634976267815\n",
      "epoch 79, loss 0.01597120240330696\n",
      "epoch 80, loss 0.015792852267622948\n",
      "epoch 81, loss 0.015616562217473984\n",
      "epoch 82, loss 0.015442161820828915\n",
      "epoch 83, loss 0.015269688330590725\n",
      "epoch 84, loss 0.01509921345859766\n",
      "epoch 85, loss 0.014930608682334423\n",
      "epoch 86, loss 0.01476388517767191\n",
      "epoch 87, loss 0.014599011279642582\n",
      "epoch 88, loss 0.014435943216085434\n",
      "epoch 89, loss 0.014274772256612778\n",
      "epoch 90, loss 0.014115341939032078\n",
      "epoch 91, loss 0.013957769609987736\n",
      "epoch 92, loss 0.013801815919578075\n",
      "epoch 93, loss 0.01364777609705925\n",
      "epoch 94, loss 0.01349536795169115\n",
      "epoch 95, loss 0.013344651088118553\n",
      "epoch 96, loss 0.013195580802857876\n",
      "epoch 97, loss 0.013048281893134117\n",
      "epoch 98, loss 0.012902543880045414\n",
      "epoch 99, loss 0.012758448719978333\n",
      "epoch 100, loss 0.012616032734513283\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "'''\n",
    "STEP 1: CREATE MODEL CLASS\n",
    "'''\n",
    "class LinearRegressionModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 2: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "\n",
    "model = LinearRegressionModel(input_size, output_size)\n",
    "\n",
    "#####################\n",
    "# USE GPU FOR MODEL #\n",
    "#####################\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "'''\n",
    "STEP 3: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 5: TRAIN THE MODEL\n",
    "'''\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    # Convert numpy array to torch Variable\n",
    "    \n",
    "    #####################\n",
    "    # USE GPU FOR MODEL #\n",
    "    #####################\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        \n",
    "        inputs = Variable(torch.from_numpy(x_train).cuda())\n",
    "        labels = Variable(torch.from_numpy(y_train).cuda())\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        inputs = Variable(torch.from_numpy(x_train))\n",
    "        labels = Variable(torch.from_numpy(y_train))\n",
    "    \n",
    "    # Clear gradients w.r.t. parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward to get output\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Calculate Loss\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Getting gradients w.r.t. parameters\n",
    "    loss.backward()\n",
    "    \n",
    "    # Updating parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    print (f'epoch {epoch}, loss {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단순 **회귀 분석 기초**\n",
    "    - $y = Ax + B$\n",
    "    - $y = 2x + 1$\n",
    "- 단순 회귀 분석의 **예**\n",
    "- 회귀 분석의 **예**\n",
    "    - 각 점들과 선의 사이의 거리를 최소화\n",
    "        - MSE를 통해 \"거리\" 계산\n",
    "        - 그라디언트들 계산\n",
    "        - 파라미터들을 통해 파라미터들 업데이트 = 파라미터들 - 학습률 * 그라디언트들\n",
    "        - 파라미터 A와 B를 천천히 업데이트한다. y = 2x + 1 형태를 갖는 y와 x 사이의 선형 관계를 모델링 한다\n",
    "- 선형 회귀분석 모델 생성 **모델**, **CPU와 GPU**의 경우\n",
    "    - Step 1: 모델 클래스 생성\n",
    "    - Step 2: 모델 클래스 인스턴스화\n",
    "    - Step 3: 손실 클래스 인스턴스화\n",
    "    - Step 4: 최적화 클래스 인스턴스화\n",
    "    - Step 5: 모델 학습시키기\n",
    "- **GPU** 옵션에서 켜져 있어야 할 것\n",
    "    - model\n",
    "    - variables\n",
    "- **GPU** 사용법?\n",
    "    - model_name.cuda()\n",
    "    - variable_name.cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
